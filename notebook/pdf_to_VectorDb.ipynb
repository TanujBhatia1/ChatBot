{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe8398f",
   "metadata": {},
   "source": [
    "RAG Pipeline : Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1d03ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ChatBotTanuj\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d80e8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read All the pdf files from the directory\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    ###Process all pdf files in the directory\n",
    "\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files in directory {pdf_directory}\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"Processing file: {pdf_file}\")\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata[\"source\"] = pdf_file.name\n",
    "                doc.metadata[\"file_type\"] = \"pdf\"\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"Loaded {len(documents)} documents from {pdf_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {pdf_file}: {e}\")\n",
    "    \n",
    "    return all_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae77ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PDF files in directory ../data\n",
      "Processing file: ..\\data\\pdf\\Computer_vision_narrated.pdf\n",
      "Loaded 4 documents from ..\\data\\pdf\\Computer_vision_narrated.pdf\n",
      "Processing file: ..\\data\\pdf\\Research Findings.pdf\n",
      "Loaded 1 documents from ..\\data\\pdf\\Research Findings.pdf\n",
      "Processing file: ..\\data\\pdf\\Timeline For Speech-to-Speech AI Sales Training Final.pdf\n",
      "Loaded 4 documents from ..\\data\\pdf\\Timeline For Speech-to-Speech AI Sales Training Final.pdf\n",
      "Total documents loaded: [Document(metadata={'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 0, 'file_type': 'pdf'}, page_content='COMPUTER \\nVISION \\nPRESENTATION'), Document(metadata={'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 1, 'file_type': 'pdf'}, page_content='I N T RO D U C T I O N  \\nTO  C O M P U T E R  \\nV I S I O N\\n• Computer vision is a field of study \\nthat focuses on enabling \\ncomputers to interpret and \\nunderstand visual information \\nfrom the world around us. It \\ninvolves developing algorithms, \\ntechniques, and systems that can \\nanalyze and process visual data \\nfrom various sources such as \\nimages, videos, and cameras.'), Document(metadata={'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 2, 'file_type': 'pdf'}, page_content='APPLICATIONS OF COMPUTER VISION\\n• Computer vision has numerous applications in various fields including:\\n• * Self-driving cars\\n• * Surveillance systems\\n• * Medical imaging analysis\\n• * Facial recognition\\n• * Object detection and tracking'), Document(metadata={'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 3, 'file_type': 'pdf'}, page_content='S U M M A RY\\nIn conclusion, computer vision is a \\nrapidly growing field that has the \\npotential to revolutionize many \\nindustries. Its applications are \\ndiverse and have far-reaching \\nimplications for fields such as \\nmedicine, transportation, and \\nsecurity.'), Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Research Findings.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Research Findings.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Research Findings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'file_type': 'pdf'}, page_content='Research Findings \\nDiarization Performance (NeMo) \\n●\\u200b Speaker Identification: Assigning wrong speaker  \\n \\n●\\u200b Unknown Speaker : Minimal \"Speaker unknown\" segments (typically at conversation \\nstart/end) \\n  \\nTranscription Quality (Whisper) \\n●\\u200b Accuracy:  Model is hallucinating based on word level transcription. \\n \\n●\\u200b Speech Recognition: Can’t recognize the company name, jargon. \\n \\n●\\u200b Natural Speech: Captures hesitations, false starts, and conversational markers \\naccurately \\n \\n \\n  \\nConclusion \\nThese models have been tested on the provided audio dataset containing 10 audios.  \\nThe finding suggests that the speaker assignment is wrong at some places and assigning \\nunknown speakers too. Although, the transcription is better but it lacks jargon in the speech \\nand also adds hallucinations.'), Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'file_type': 'pdf'}, page_content='Speech-to-Speech AI Sales Training \\nPlatform Development Timeline \\n \\n \\n \\nMonth 1: Development & LLM Integration (via Chat) \\n●\\u200b Demo Development : Create chat-based prototype with persona interactions \\nand sales roleplay scenarios \\n●\\u200b Chatbot Infrastructure : Build web chat interface with session management \\nand conversation history \\n●\\u200b LLM Deployment : Deploy OpenAI LLM endpoints with persona-specific \\nresponse capabilities \\n●\\u200b Persona Development : Develop buyer persona profiles (IT Head, Procurement \\nManager, CEO) with industry backstories \\n \\n \\nMonth 2-3: Real-time Conversation Engine { including LLM \\nTTS and STT Integration } \\n \\n●\\u200b Real-Time Conversation Engine with streaming architecture \\n●\\u200b LLM inference optimized using NVIDIA TensorRT \\n●\\u200b Speech-to-Text and Text-to-Speech powered by NVIDIA Riva \\n●\\u200b End-to-end low-latency pipeline for real-time interaction \\n \\n \\n \\nOR \\nMonth 1.5 : Real-time Conversation Engine Using API { \\nincluding LLM TTS and STT Integration }'), Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'file_type': 'pdf'}, page_content='●\\u200b STT Integration: Configure OpenAI Whisper API for <200ms speech \\ntranscription with voice activity detection \\n●\\u200b OpenAI LLM Integration: Deploy GPT-4 Realtime API with persona-specific \\nprompts for dynamic buyer personalities \\n●\\u200b ElevenLabs TTS Integration: Implement ElevenLabs API for natural voice \\nsynthesis achieving <100ms audio latency \\n●\\u200b Conversation Engine: Build unified STT → OpenAI LLM → ElevenLabs pipeline \\nwith 20+ sales scenarios and interruption handling \\n \\nMonth 4: Production Deployment & Launch {Docker} \\n●\\u200b Deploy scalable, docker-based production environment with auto-scaling\\u200b\\n \\n●\\u200b Set up and configure full production environment\\u200b\\n \\n●\\u200b Implement session monitoring with real-time performance analytics \\ndashboards\\u200b\\n \\n●\\u200b Establish automated troubleshooting and customer support systems'), Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'file_type': 'pdf'}, page_content='!………………………………….. Costing ……...…………………...………! \\n \\n5 Minute APIs Service Cost : \\u200b\\n \\nService \\n1 Min Cost (₹) 5 Min Cost (₹) \\nSpeech-to-Text \\n0.532 \\n2.66 \\nLLM \\n3.105 \\n15.53 \\nText-to-Speech \\n10.64 \\n53.2 \\nTotal (per \\nminute) \\n14.28 \\n71.39 \\n\\u200b\\nCabinet {On-prem} 48GB GPU Hardware Cost :  \\n●\\u200b\\n \\n16+16_GPU_Cabinte.pdf\\n●\\u200b\\nRTX 5060 32GB GPU Pricing : ₹216,850\\u200b\\n \\nExplanation: \\n\\u200b\\n \\nAPI Service \\nINR Cost per 1 Min \\n(140 words) \\nOfficial Documentation URL \\nOpenAI (Speech-to-Text) \\n₹0.532 \\nhttps://platform.openai.com/pricing \\nOpenAI GPT-4o (LLM Processing) \\n₹3.105 \\nhttps://platform.openai.com/pricing \\nElevenLabs TTS (Text-to-Speech) \\n₹10.64 \\nhttps://elevenlabs.io/pricing \\nTotal Cost (Premium: Whisper + \\nGPT-4o + ElevenLabs) \\n₹14.28 \\nCombined from above sources \\n \\nHardware Costing : 32 GB GPU cabinet \\n \\nProduct \\nQuantity \\nPrice \\nSubtotal \\nIntel Core i7-12700 12th Generation Processor (Up to \\n4.90 GHz / 12 Cores / 20 Threads) \\n1 \\n₹25,150 \\n₹25,150 \\nAsus Prime Z790-P-CSM LGA1700 ATX Motherboard \\n(PRIME Z790-P-CSM) \\n1 \\n₹22,750 \\n₹22,750 \\nAdata XPG Lancer Blade 32 GB (16 GB×2) DDR5 6000 \\nMHz (AX5U6000C4816G-DTLABWH) 1.1 V \\n1 \\n₹8,900 \\n₹8,900'), Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'file_type': 'pdf'}, page_content='Colorful RTX 5060 Ti NB Duo 16 GB-V GDDR7 Graphics \\nCard \\n3 \\n₹46,200 \\n₹138,600 \\nAnt Esports FG850 850 Watt 80 Plus Gold Power Supply \\n(FG850) \\n1 \\n₹6,050 \\n₹6,050 \\nWD Blue SN5000 2 TB PCIe Gen4 NVMe M.2 Internal \\nSSD (WDS200T4B0E) \\n1 \\n₹11,000 \\n₹11,000 \\nAnt Esports 511 Air 5F E-ATX Mid Tower Cabinet Black \\n(AESP0371) \\n1 \\n₹4,400 \\n₹4,400 \\nTotal \\n9 \\n \\n₹216,850 \\n \\n \\n \\n \\n \\n \\n \\n!.............................................................................................!')]\n"
     ]
    }
   ],
   "source": [
    "all_pdf_documents = process_all_pdfs(\"../data\")\n",
    "print(f\"Total documents loaded: {all_pdf_documents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f50bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    ### Split documents into smaller chunks\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split into {len(split_docs)} chunks.\")\n",
    "\n",
    "    # example of chunk \n",
    "    if split_docs:\n",
    "        print(\"Example chunk:\")\n",
    "        print(\"Chunks : \", split_docs[0].page_content[:500])  # Print first 500 characters of the first chunk\n",
    "        print(\"Metadata:\", split_docs[0].metadata)\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad1fa2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 10 chunks.\n",
      "Example chunk:\n",
      "Chunks :  COMPUTER \n",
      "VISION \n",
      "PRESENTATION\n",
      "Metadata: {'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 0, 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b807383",
   "metadata": {},
   "source": [
    "Embedding and VectorStore DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcd0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import uuid\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657670ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x24c20292fe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    ###Handles document embedding generation using SetenceTransformer\n",
    "\n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize the embedding manager\n",
    "\n",
    "        Args: \n",
    "            model_name (str): HuggingFace model name for Sentence embeddings\n",
    "\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise \n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "\n",
    "        Args:\n",
    "            texts (List[str]): List of text strings to embed\n",
    "        Returns:\n",
    "            np.ndarray: Array of embeddings\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model is not loaded.\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts......\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "    def add_documents(self, documents: List[Any], embeddings:np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "\n",
    "        Args:\n",
    "            documents (List[Any]): _description_\n",
    "            embeddings (np.ndarray): _description_\n",
    "        \"\"\"\n",
    "        if len(documents)!= len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store....\")\n",
    "        \n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc,embedding) in enumerate(zip(documents, embeddings)):\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            #prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadata.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text,\n",
    "                embeddings=embeddings_list\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store.\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "    \n",
    "\n",
    "## initialize embedding manager\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073fbf32",
   "metadata": {},
   "source": [
    "Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0905dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store initialized. Collection: pdf_documents\n",
      "Existing documents in collection: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x24c71fcd510>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a ChromaDB vector Store\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "        \n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromaDB client and collection\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # create persistant ChromaDB client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            \n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description:\":\"Pdf document embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector Store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def add_documents(self, documents: List[Any], embeddings:np.ndarray):\n",
    "        \"\"\"\n",
    "        Add documents and their embeddings to the vector store\n",
    "\n",
    "        Args:\n",
    "            documents (List[Any]): _description_\n",
    "            embeddings (np.ndarray): _description_\n",
    "        \"\"\"\n",
    "        if len(documents)!= len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store....\")\n",
    "        \n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for i, (doc,embedding) in enumerate(zip(documents, embeddings)):\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            \n",
    "            #prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            # embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text,\n",
    "                embeddings=embeddings_list\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store.\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "            raise\n",
    "            \n",
    "            \n",
    "vectorstore = VectorStore()\n",
    "vectorstore\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ea7727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 0, 'file_type': 'pdf'}, page_content='COMPUTER \\nVISION \\nPRESENTATION'),\n",
       " Document(metadata={'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 1, 'file_type': 'pdf'}, page_content='I N T RO D U C T I O N  \\nTO  C O M P U T E R  \\nV I S I O N\\n• Computer vision is a field of study \\nthat focuses on enabling \\ncomputers to interpret and \\nunderstand visual information \\nfrom the world around us. It \\ninvolves developing algorithms, \\ntechniques, and systems that can \\nanalyze and process visual data \\nfrom various sources such as \\nimages, videos, and cameras.'),\n",
       " Document(metadata={'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 2, 'file_type': 'pdf'}, page_content='APPLICATIONS OF COMPUTER VISION\\n• Computer vision has numerous applications in various fields including:\\n• * Self-driving cars\\n• * Surveillance systems\\n• * Medical imaging analysis\\n• * Facial recognition\\n• * Object detection and tracking'),\n",
       " Document(metadata={'producer': 'Microsoft® PowerPoint® 2019', 'creator': 'Microsoft® PowerPoint® 2019', 'creationdate': '2025-11-24T18:05:36+05:30', 'source': 'Computer_vision_narrated.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Computer_vision_narrated.pdf', 'total_pages': 4, 'format': 'PDF 1.7', 'title': 'Computer Vision Presentation', 'author': 'Käch, Timon', 'subject': '', 'keywords': '', 'moddate': '2025-11-24T18:05:36+05:30', 'trapped': '', 'modDate': \"D:20251124180536+05'30'\", 'creationDate': \"D:20251124180536+05'30'\", 'page': 3, 'file_type': 'pdf'}, page_content='S U M M A RY\\nIn conclusion, computer vision is a \\nrapidly growing field that has the \\npotential to revolutionize many \\nindustries. Its applications are \\ndiverse and have far-reaching \\nimplications for fields such as \\nmedicine, transportation, and \\nsecurity.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m141 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Research Findings.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Research Findings.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Research Findings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'file_type': 'pdf'}, page_content='Research Findings \\nDiarization Performance (NeMo) \\n●\\u200b Speaker Identification: Assigning wrong speaker  \\n \\n●\\u200b Unknown Speaker : Minimal \"Speaker unknown\" segments (typically at conversation \\nstart/end) \\n  \\nTranscription Quality (Whisper) \\n●\\u200b Accuracy:  Model is hallucinating based on word level transcription. \\n \\n●\\u200b Speech Recognition: Can’t recognize the company name, jargon. \\n \\n●\\u200b Natural Speech: Captures hesitations, false starts, and conversational markers \\naccurately \\n \\n \\n  \\nConclusion \\nThese models have been tested on the provided audio dataset containing 10 audios.  \\nThe finding suggests that the speaker assignment is wrong at some places and assigning \\nunknown speakers too. Although, the transcription is better but it lacks jargon in the speech \\nand also adds hallucinations.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'file_type': 'pdf'}, page_content='Speech-to-Speech AI Sales Training \\nPlatform Development Timeline \\n \\n \\n \\nMonth 1: Development & LLM Integration (via Chat) \\n●\\u200b Demo Development : Create chat-based prototype with persona interactions \\nand sales roleplay scenarios \\n●\\u200b Chatbot Infrastructure : Build web chat interface with session management \\nand conversation history \\n●\\u200b LLM Deployment : Deploy OpenAI LLM endpoints with persona-specific \\nresponse capabilities \\n●\\u200b Persona Development : Develop buyer persona profiles (IT Head, Procurement \\nManager, CEO) with industry backstories \\n \\n \\nMonth 2-3: Real-time Conversation Engine { including LLM \\nTTS and STT Integration } \\n \\n●\\u200b Real-Time Conversation Engine with streaming architecture \\n●\\u200b LLM inference optimized using NVIDIA TensorRT \\n●\\u200b Speech-to-Text and Text-to-Speech powered by NVIDIA Riva \\n●\\u200b End-to-end low-latency pipeline for real-time interaction \\n \\n \\n \\nOR \\nMonth 1.5 : Real-time Conversation Engine Using API { \\nincluding LLM TTS and STT Integration }'),\n",
       " Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'file_type': 'pdf'}, page_content='●\\u200b STT Integration: Configure OpenAI Whisper API for <200ms speech \\ntranscription with voice activity detection \\n●\\u200b OpenAI LLM Integration: Deploy GPT-4 Realtime API with persona-specific \\nprompts for dynamic buyer personalities \\n●\\u200b ElevenLabs TTS Integration: Implement ElevenLabs API for natural voice \\nsynthesis achieving <100ms audio latency \\n●\\u200b Conversation Engine: Build unified STT → OpenAI LLM → ElevenLabs pipeline \\nwith 20+ sales scenarios and interruption handling \\n \\nMonth 4: Production Deployment & Launch {Docker} \\n●\\u200b Deploy scalable, docker-based production environment with auto-scaling\\u200b\\n \\n●\\u200b Set up and configure full production environment\\u200b\\n \\n●\\u200b Implement session monitoring with real-time performance analytics \\ndashboards\\u200b\\n \\n●\\u200b Establish automated troubleshooting and customer support systems'),\n",
       " Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'file_type': 'pdf'}, page_content='!………………………………….. Costing ……...…………………...………! \\n \\n5 Minute APIs Service Cost : \\u200b\\n \\nService \\n1 Min Cost (₹) 5 Min Cost (₹) \\nSpeech-to-Text \\n0.532 \\n2.66 \\nLLM \\n3.105 \\n15.53 \\nText-to-Speech \\n10.64 \\n53.2 \\nTotal (per \\nminute) \\n14.28 \\n71.39 \\n\\u200b\\nCabinet {On-prem} 48GB GPU Hardware Cost :  \\n●\\u200b\\n \\n16+16_GPU_Cabinte.pdf\\n●\\u200b\\nRTX 5060 32GB GPU Pricing : ₹216,850\\u200b\\n \\nExplanation: \\n\\u200b\\n \\nAPI Service \\nINR Cost per 1 Min \\n(140 words) \\nOfficial Documentation URL \\nOpenAI (Speech-to-Text) \\n₹0.532 \\nhttps://platform.openai.com/pricing \\nOpenAI GPT-4o (LLM Processing) \\n₹3.105 \\nhttps://platform.openai.com/pricing \\nElevenLabs TTS (Text-to-Speech) \\n₹10.64 \\nhttps://elevenlabs.io/pricing \\nTotal Cost (Premium: Whisper + \\nGPT-4o + ElevenLabs) \\n₹14.28 \\nCombined from above sources \\n \\nHardware Costing : 32 GB GPU cabinet \\n \\nProduct \\nQuantity \\nPrice \\nSubtotal \\nIntel Core i7-12700 12th Generation Processor (Up to \\n4.90 GHz / 12 Cores / 20 Threads) \\n1 \\n₹25,150 \\n₹25,150 \\nAsus Prime Z790-P-CSM LGA1700 ATX Motherboard'),\n",
       " Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'file_type': 'pdf'}, page_content='Product \\nQuantity \\nPrice \\nSubtotal \\nIntel Core i7-12700 12th Generation Processor (Up to \\n4.90 GHz / 12 Cores / 20 Threads) \\n1 \\n₹25,150 \\n₹25,150 \\nAsus Prime Z790-P-CSM LGA1700 ATX Motherboard \\n(PRIME Z790-P-CSM) \\n1 \\n₹22,750 \\n₹22,750 \\nAdata XPG Lancer Blade 32 GB (16 GB×2) DDR5 6000 \\nMHz (AX5U6000C4816G-DTLABWH) 1.1 V \\n1 \\n₹8,900 \\n₹8,900'),\n",
       " Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': 'Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'file_path': '..\\\\data\\\\pdf\\\\Timeline For Speech-to-Speech AI Sales Training Final.pdf', 'total_pages': 4, 'format': 'PDF 1.4', 'title': 'Timeline For Speech-to-Speech AI Sales Training', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'file_type': 'pdf'}, page_content='Colorful RTX 5060 Ti NB Duo 16 GB-V GDDR7 Graphics \\nCard \\n3 \\n₹46,200 \\n₹138,600 \\nAnt Esports FG850 850 Watt 80 Plus Gold Power Supply \\n(FG850) \\n1 \\n₹6,050 \\n₹6,050 \\nWD Blue SN5000 2 TB PCIe Gen4 NVMe M.2 Internal \\nSSD (WDS200T4B0E) \\n1 \\n₹11,000 \\n₹11,000 \\nAnt Esports 511 Air 5F E-ATX Mid Tower Cabinet Black \\n(AESP0371) \\n1 \\n₹4,400 \\n₹4,400 \\nTotal \\n9 \\n \\n₹216,850 \\n \\n \\n \\n \\n \\n \\n \\n!.............................................................................................!')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff4363a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 10 texts......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (10, 384)\n",
      "Adding 10 documents to vector store....\n",
      "Successfully added 10 documents to vector store.\n",
      "Total documents in collection: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate embeddings\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "## store in vector db\n",
    "vectorstore.add_documents(chunks, embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50767ee",
   "metadata": {},
   "source": [
    "Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d649e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"handles retrieval of relevant documents from vector store for RAG\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the RAG retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store (VectorStore): Instance of the VectorStore\n",
    "            embedding_manager (EmbeddingManager): Instance of the EmbeddingManager\n",
    "            top_k (int): Number of top similar documents to retrieve\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int=2 , score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve top_k similar documents for the given query\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query string\n",
    "            top_k (int): Number of top similar documents to retrieve\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: List of retrieved documents with metadata\n",
    "        \"\"\"\n",
    "        print(f\"Generating embedding for query: {query}\")\n",
    "        print(f\"Top k : {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        #Generate embedding for query\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search query in vector store\n",
    "        try:\n",
    "            \n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                embeddings = results['embeddings'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, embeddings)):\n",
    "                    \n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retieved_docs.append({\n",
    "                            \"id\": doc_id,\n",
    "                            \"document\": document,\n",
    "                            \"metadata\": metadata,\n",
    "                            \"similarity_score\": similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i+1\n",
    "                        })\n",
    "                        \n",
    "                print(f\"Retrieved {len(retieved_docs)} documents after applying score threshold.\")\n",
    "            else:\n",
    "                print(\"No documents retrieved from vector store.\") \n",
    "                \n",
    "            return retieved_docs\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving documents: {e}\")\n",
    "            return []\n",
    "         \n",
    "         \n",
    "ragRetriever = RAGRetriever(vectorstore, embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4816c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x24c224e46a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0247bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding for query: Give me an overview of the document\n",
      "Top k : 2, Score threshold: 0.0\n",
      "Generating embeddings for 1 texts......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Error retrieving documents: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragRetriever.retrieve(\"Give me an overview of the document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd77af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatBotTanuj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
